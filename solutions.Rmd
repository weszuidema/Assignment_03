---
title: "Assignment 3 Solutions"
author: "Wesley Zuidema"
date: "April 21, 2016"
output: pdf_document
---

```{r}
library("foreign")
library("dplyr")
library("broom")
library("ggplot2")
library("texreg")

# Ensures results are identical each time you run the simulation
set.seed(1234)

# Ensures we don't have to rerun things that have already been run when we knitr
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE)
```

Problem 1

```{r}
nunn <- read.dta("Nunn_Wantchekon_AER_2011.dta") %>% tbl_df()
mod1 <- lm(trust_neighbors ~ exports + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn) 

# str(nunn)
# attr(nunn, "var.labels")
```

Interpret the coefficient's magnitude and statistical significance.
  The export of slaves is negatively correlated with modern levels of trust. We reject the null hypothesis at the .01 signifiance level. I can't assess the magnitude without knowing the units or effect size.

Some questions on p-values

    What is the null hypothesis of the t-tests?
      The null hypothesis is that the coefficient of "exports" is zero.
    Explain the meaning of the p-value
      The probability of observing as extreme or more extreme data if the null hypothesis is true.
    Is the p-value the probability that the null hypothesis is correct?
      No, it is not. The p value is only meaningful because it assumes the null hypothesis is true.

What other variables does Nunn include? Include those in Table 1, Model 1. Run that regression.

```{r}
nunn <- mutate(nunn, exports_area = (exports / export_area))
nunn <- mutate(nunn, exports_pop = (exports / export_pop))
mod2 <- lm(trust_neighbors ~ exports_area + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn)
mod3 <- lm(trust_neighbors ~ exports_pop + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn)
mod4 <- lm(trust_neighbors ~ log(1 + exports) + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn)
mod5 <- lm(trust_neighbors ~ log(1 + exports_area) + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn)
mod6 <- lm(trust_neighbors ~ log(1 + exports_pop) + age + age2 + male + urban_dum + factor(occupation) + factor(religion) + factor(living_conditions) + factor(education) + district_ethnic_frac + frac_ethnicity_in_district + factor(isocode), data = nunn)

htmlreg(list(mod1, mod2, mod3, mod4, mod5, mod6), file = "regtable.html", stars = c())
```


Does the R^2 match that in Table 1?

Do the standard errors match those in Table 1? Any guesses why?

Run the regression in Table 1, model 6. Why is it "log(1 + exports / pop)" instead of "log(exports / pop)"?

```{r}
resampler_coef <- function(mod, .data, iter = 1) {
  # Remove missing values
  .data <- na.omit(.data)
  # Coefficients
  beta <- coef(mod)
  # mod$terms contains the formula used in the regression
  X <- model.matrix(mod$terms, data = .data)
  # estimate of std. dev. of errors
  sigma <- sqrt(sum(mod$residuals ^ 2) / mod$df.residual)
  # This produces the same result
  # sigma <- summary(mod1)$sigma  
  # Number of observations
  n <- nrow(X)
  # Name of dependent variable
  outcome_var_name <- all.vars(mod$terms)[1]
  # List to save results
  results <- vector(mode = "list", length = iter)
  for (i in seq_len(iter)) {
    # draw errors
    errors <- rnorm(n, mean = 0, sd = sigma)
    # create new outcome variable from errors
    y <- X %*% beta + errors
    # replace outcome variable
    .data[[outcome_var_name]] <- y
    # run regression
    newmod <- lm(mod$terms, data = .data)
    # Save coefficients as a data frame to the list
    results[[i]] <- tidy(newmod) %>% mutate(.iter = i)
  }
  # Convert the list of data frames to a single data frame by stacking the iterations
  bind_rows(results)
}
```


    Plot the distributions of the coefficients
    Calculate the correlation matrix of the coefficients. How similar is it to that from vcov?

F-test example

    Run F-tests of the multiple regression model vs. the model with no controls.
    Run and interpet an F-test on some reasonable group of variables.

F-test simulations

```{r}
resampler_models <- function(mod, .data, iter = 1) {
  # Remove missing values
  .data <- na.omit(.data)
  # Coefficients
  beta <- coef(mod)
  # mod$terms contains the formula used in the regression
  X <- model.matrix(mod$terms, data = .data)
  # estimate of std. dev. of errors
  sigma <- sqrt(sum(mod$residuals ^ 2) / mod$df.residual)
  # This produces the same result
  # sigma <- summary(mod1)$sigma  
  # Number of observations
  n <- nrow(X)
  # Name of dependent variable
  outcome_var_name <- all.vars(mod$terms)[1]
  # List to save results
  results <- vector(mode = "list", length = iter)
  for (i in seq_len(iter)) {
    # draw errors
    errors <- rnorm(n, mean = 0, sd = sigma)
    # create new outcome variable from errors
    y <- X %*% beta + errors
    # replace outcome variable
    .data[[outcome_var_name]] <- y
    # run regression
    newmod <- lm(mod$terms, data = .data)
    # Save model stats as a data frame to the list
    results[[i]] <- glimpse(newmod) %>% mutate(.iter = i)
  }
  # Convert the list of data frames to a single data frame by stacking the iterations
  bind_rows(results)
}
```

Bootstrap example

```{r}
nunn_bootstrapped <- bootstrap(nunn, 1)

bootstrap(nunn, 1024) %>%
  do(tidy(lm(trust_neighbors ~ exports, data = nunn)))
```

Example of a single bootstrap replication. We draw N observations with replacement from the original data.
To get bootstrap standard errors, we draw m replications, run the regression, and save the estimates. 
There are several ways to calculate standard errors from bootstraped replications.

    Calculate the standard error from these simulations by taking the standard deviation of the estimates.
    Calculate the confidence interval using the 2.5% and 97.5% quantiles in the replications

However, in the bootstrap, we should draw the bootstrap samples the same way the sample was drawn from the population. Why might this not be the case in what we just did? 

Multiple comparisons and F-test

```{r}
noise <- data.frame(matrix(rnorm(2100), nrow = 100, ncol = 21))
summary(lm(noise))
```


    How many variables have t-tests that are significant?
    Is the F-test significant?
    Explain the difference
